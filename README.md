We say that an algorithm is O(f(n)) if the number of simple operations the computer has to do is eventually less than a constant times f(n), as n increases.

*f(n) is a function with the input of n

• f(n) could be linear (f(n) = n)

• f(n) could be quadratic (f(n) = n^2)

• f(n) could be constant (f(n) = 1)

• f(n) could be something entirely different
